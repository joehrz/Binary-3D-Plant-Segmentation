{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "# Then your import should work\n",
    "from src.models.pointnetplusplus import PointNetPlusPlus\n",
    "from src.configs.config import Config\n",
    "config_dir = os.path.join(parent_dir, 'src', 'configs', 'default_config.yaml')\n",
    "config = Config(config_dir)\n",
    "def load_trained_model(checkpoint_path, num_classes=2, device=\"cpu\"):\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "\n",
    "    model = PointNetPlusPlus(num_classes=num_classes).to(device)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def infer_on_new_data(model, points, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Now we assume 'points' is already shaped (num_points,3) or at least \n",
    "    we've done any sampling/padding outside. So we just do the forward pass.\n",
    "    \"\"\"\n",
    "    points_torch = torch.tensor(points, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(points_torch)  # shape (1, N, num_classes)\n",
    "        preds = outputs.argmax(dim=-1).squeeze(0)\n",
    "    return preds.cpu().numpy()\n",
    "\n",
    "def plot_combined_original_and_seg(\n",
    "    orig_points, orig_colors,\n",
    "    seg_points, seg_labels,\n",
    "    out_file=\"combined_visual.png\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a figure with 2 subplots side by side:\n",
    "      - Subplot #1: \"Downsampled Original\" (with original color)\n",
    "      - Subplot #2: Segmentation (plant=green, non-plant=red)\n",
    "    Saves to out_file.\n",
    "    Args:\n",
    "        orig_points (N,3): sample of original coords\n",
    "        orig_colors (N,3): sample of original colors in [0,1]\n",
    "        seg_points (M,3): same or similar points used for segmentation\n",
    "        seg_labels (M,): 0=non-plant, 1=plant\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "    # Subplot #1: Original color\n",
    "    ax1.scatter(orig_points[:, 0],\n",
    "                orig_points[:, 1],\n",
    "                orig_points[:, 2],\n",
    "                c=orig_colors,\n",
    "                s=2)\n",
    "    ax1.set_title(\"Downsampled Original\")\n",
    "    ax1.set_xlabel(\"X\")\n",
    "    ax1.set_ylabel(\"Y\")\n",
    "    ax1.set_zlabel(\"Z\")\n",
    "\n",
    "    # Subplot #2: Segmentation\n",
    "    plant_mask = (seg_labels == 1)\n",
    "    nonplant_mask = (seg_labels == 0)\n",
    "    ax2.scatter(seg_points[nonplant_mask, 0],\n",
    "                seg_points[nonplant_mask, 1],\n",
    "                seg_points[nonplant_mask, 2],\n",
    "                c='red', s=2, label='Non-Plant')\n",
    "    ax2.scatter(seg_points[plant_mask, 0],\n",
    "                seg_points[plant_mask, 1],\n",
    "                seg_points[plant_mask, 2],\n",
    "                c='green', s=2, label='Plant')\n",
    "    ax2.set_title(\"Segmentation (Plant/Non-Plant)\")\n",
    "    ax2.set_xlabel(\"X\")\n",
    "    ax2.set_ylabel(\"Y\")\n",
    "    ax2.set_zlabel(\"Z\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_file)\n",
    "    plt.show()\n",
    "    print(f\"[INFO] Combined figure saved to {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_points(points, colors):\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.scatter(points[:, 0],\n",
    "               points[:, 1],\n",
    "               points[:, 2],\n",
    "               c=colors, s=1, alpha=0.5)\n",
    "\n",
    "    \n",
    "    #ax.set_title(title)\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "\n",
    "    plt.savefig('full_wheat_point_cloud.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_save_path = os.path.join(parent_dir, config.model.save_dir, 'best_model_train.pth')\n",
    "\n",
    "# 1) load trained model\n",
    "model = load_trained_model(\n",
    "    checkpoint_path=model_save_path,\n",
    "    num_classes=2,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# 2) load a .ply cloud with color\n",
    "file_name = os.path.join(parent_dir, 'data', 'wheat_data', 'raw', 'Wheat_Alsen_F8_2023-06-30-2013_fused_output.ply')\n",
    "pcd = o3d.io.read_point_cloud(file_name)\n",
    "points = np.asarray(pcd.points)   # shape (N,3)\n",
    "colors = np.asarray(pcd.colors)   # shape (N,3) in [0,1]\n",
    "visualize_points(points, colors)\n",
    "# We'll do a uniform sampling step ourselves to keep 4096 points (if N>4096)\n",
    "N = len(points)\n",
    "if N > 4096:\n",
    "    idx_sample = np.random.choice(N, 4096, replace=False)\n",
    "    ds_points = points[idx_sample]\n",
    "    ds_colors = colors[idx_sample]\n",
    "else:\n",
    "    ds_points = points\n",
    "    ds_colors = colors\n",
    "\n",
    "# 3) run inference using same ds_points\n",
    "#    (Or you could do a separate chunk approach if needed.)\n",
    "predicted_labels = infer_on_new_data(model, ds_points, device=device)\n",
    "print(\"Predicted labels shape:\", predicted_labels.shape)\n",
    "\n",
    "# 4) Combine into side-by-side subplots\n",
    "plot_combined_original_and_seg(\n",
    "    ds_points, ds_colors,   # \"Left\" subplot: original color\n",
    "    ds_points, predicted_labels,  # \"Right\" subplot: segmentation\n",
    "    out_file=\"combined_visual.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "def open3d_visualize_segmentation(points, labels):\n",
    "    \"\"\"\n",
    "    points: (N, 3)\n",
    "    labels: (N,) -> 0=non-plant, 1=plant\n",
    "    \"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    # Build colors array\n",
    "    colors = np.zeros_like(points)  # shape (N,3)\n",
    "    colors[labels == 1] = [0,1,0]   # plant -> green\n",
    "    colors[labels == 0] = [1,0,0]   # non-plant -> red\n",
    "\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd], window_name=\"Plant vs. Non-Plant\")\n",
    "\n",
    "open3d_visualize_segmentation(ds_points, predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
